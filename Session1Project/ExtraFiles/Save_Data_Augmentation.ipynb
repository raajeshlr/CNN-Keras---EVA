{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Save Data Augmentation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sw4nNhM8mN2z",
        "outputId": "72dfb7d5-10b8-40c1-90b0-1398d3fc53e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "from keras.utils import np_utils\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "#tf.enable_eager_execution()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VeLRe4cBmbu_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1b75c2ae-3f76-4ea7-d3a6-c750b5c470d0"
      },
      "source": [
        "(train_features, train_labels), (test_features, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "num_train, img_channels, img_rows, img_cols =  train_features.shape\n",
        "num_test, _, _, _ =  test_features.shape\n",
        "num_classes = len(np.unique(train_labels))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w9Men1oDmesN",
        "colab": {}
      },
      "source": [
        "train_features = train_features.astype('float32')/255\n",
        "test_features = test_features.astype('float32')/255\n",
        "# convert class labels to binary class labels\n",
        "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = np_utils.to_categorical(test_labels, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhAmhrsOLQRq",
        "colab_type": "code",
        "outputId": "10a6c490-5b7b-45c5-8273-33892a2636b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_features.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcQrJ2EnKUvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_crop(input_image,padding_pixels=4,random_crop_size=(32,32)):\n",
        "    assert input_image.shape[2]==3\n",
        "\n",
        "    #pad for 4 pixels\n",
        "    img = cv2.copyMakeBorder(input_image,padding_pixels,padding_pixels,padding_pixels,padding_pixels,cv2.BORDER_REPLICATE)\n",
        "    height , width =img.shape[0],img.shape[1]\n",
        "    dy,dx = random_crop_size\n",
        "    x = np.random.randint(0,width - dx + 1)\n",
        "    y = np.random.randint(0,height - dy + 1)\n",
        "    return img[y:(y+dy),x:(x+dx),:]\n",
        "\n",
        "#lambda_feat = lambda t : random_crop(t)\n",
        "tr_seq = list(range(len(train_features)))\n",
        "te_seq = list(range(len(test_features)))\n",
        "train_func = lambda i:random_crop(train_features[i])\n",
        "train_features = list(map(train_func,tr_seq))\n",
        "\n",
        "train_features = np.asarray(train_features)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLsU1VFWQ7n_",
        "colab_type": "code",
        "outputId": "d539dcfc-bd33-4a3c-af4e-7e73f43578b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.imshow(train_features[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2a511b08d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntJEt49pxGAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q5EigjQNmhWU",
        "colab": {}
      },
      "source": [
        "def get_cutout_eraser_and_random_crop(p=0.4,s_l=0.05,s_h=0.3,r_1=0.3,r_2=1/0.3,max_erasers_per_image=1,pixel_level=True,random_crop_size=(32,32),padding_pixels=4):\n",
        "  \n",
        "  assert max_erasers_per_image>=1 \n",
        "  def eraser(input_img):\n",
        "        v_l = np.min(input_img)\n",
        "        v_h = np.max(input_img)\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "        mx = np.random.randint(1,max_erasers_per_image+1)\n",
        "        for i in range(mx):\n",
        "          while True:\n",
        "              s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "              r = np.random.uniform(r_1, r_2)\n",
        "              w = int(np.sqrt(s / r))\n",
        "              h = int(np.sqrt(s * r))\n",
        "              left = np.random.randint(0, img_w)\n",
        "              top = np.random.randint(0, img_h)\n",
        "\n",
        "              if left + w <= img_w and top + h <= img_h:\n",
        "                  break\n",
        "\n",
        "          if pixel_level:\n",
        "              c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "          else:\n",
        "              c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "          input_img[top:top + h, left:left + w, :] = c\n",
        "        return input_img\n",
        "\n",
        "  def preprocess_image(input_image):\n",
        "    return eraser(input_image)\n",
        "  \n",
        "  return preprocess_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf7MTd6B-rYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_mean = np.mean(test_features,axis=(0,1,2))\n",
        "x_train_std = np.mean(test_features,axis=(0,1,2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2tOuprdCpqSB",
        "colab": {}
      },
      "source": [
        "datagen_aug = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=0.5,featurewise_center=True, featurewise_std_normalization=True,preprocessing_function=get_cutout_eraser_and_random_crop())\n",
        "datagen_aug.mean = np.array(x_train_mean, dtype=np.float32).reshape((1,1,3)) # ordering: [R, G, B]\n",
        "datagen_aug.std = np.array(x_train_std, dtype=np.float32).reshape((1,1,3)) # ordering: [R, G, B]\n",
        "#datagen.fit(train_features)\n",
        "train_generator = datagen_aug.flow(train_features,train_labels,batch_size=256)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlSUtRPeOIxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_mean = np.mean(test_features,axis=(0,1,2))\n",
        "x_test_std = np.mean(test_features,axis=(0,1,2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AMi1CeDsqUyv",
        "colab": {}
      },
      "source": [
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "test_datagen.mean = np.array(x_test_mean, dtype=np.float32).reshape((1,1,3)) # ordering: [R, G, B]\n",
        "test_datagen.std = np.array(x_test_std, dtype=np.float32).reshape((1,1,3)) # ordering: [R, G, B]\n",
        "test_datagen.fit(test_features)\n",
        "test_generator = test_datagen.flow(test_features,test_labels,batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZVue0KrdH2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# aug_img=np.zeros((256,32,32,3))\n",
        "# train_gen = train_generator.next()\n",
        "# aug_img[:256]= train_gen[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B_Gdr7lP-rq",
        "colab_type": "code",
        "outputId": "cf9e0ee8-4f2d-4c2c-93c9-027fbeaf2f2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "import h5py\n",
        "f = h5py.File('aug_img.hdf5', 'w')\n",
        "d = f.create_dataset('dataset', (500000,32,32,3),chunks=(256,32,32,3))\n",
        "l = f.create_dataset('labels',(500000,10),chunks=(256,10))\n",
        "\n",
        "\n",
        "batch_size=256\n",
        "EPOCHS =20\n",
        "aug_lbl=[]\n",
        "tmp=0\n",
        "for i in range(EPOCHS):\n",
        "  print(\"tmp \", tmp)\n",
        "  for j in range(len(train_generator)):\n",
        "    initial = j*batch_size+tmp\n",
        "    train_gen = train_generator.next()\n",
        "    if(j == 195 ):\n",
        "      final += 80\n",
        "      d[initial:final]= train_gen[0]\n",
        "      l[initial:final]= train_gen[1]\n",
        "      continue \n",
        "      \n",
        "    \n",
        "    final = initial + 256\n",
        "    d[initial:final]= train_gen[0]\n",
        "    l[initial:final]= train_gen[1]\n",
        "  \n",
        "  tmp = final\n",
        "\n",
        "# f.close()\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tmp  0\n",
            "tmp  50000\n",
            "tmp  100000\n",
            "tmp  150000\n",
            "tmp  200000\n",
            "tmp  250000\n",
            "tmp  300000\n",
            "tmp  350000\n",
            "tmp  400000\n",
            "tmp  450000\n",
            "tmp  500000\n",
            "tmp  550000\n",
            "tmp  600000\n",
            "tmp  650000\n",
            "tmp  700000\n",
            "tmp  750000\n",
            "tmp  800000\n",
            "tmp  850000\n",
            "tmp  900000\n",
            "tmp  950000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FzTlimoW3X_",
        "colab_type": "code",
        "outputId": "1c0a08d3-e687-40f6-c2dd-9a65f485a98a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# tmp_aug=[]\n",
        "# tmp_not_aug=[]\n",
        "# for i in range(len(train_generator_aug)):\n",
        "#   tmp_aug.append(train_generator_aug.next())\n",
        "#   tmp_not_aug.append(train_not_aug.next())\n",
        "  \n",
        "\n",
        "##contains the 256 images batch --\n",
        "#aug_images = np.asarray(tmp)\n",
        "#wo_aug_images = "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Za7Xax0zyZc2"
      },
      "source": [
        "#Resnet Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xp2uGvCQcTq",
        "colab_type": "code",
        "outputId": "5aac88d5-54cd-465e-cb60-a59b6f4c8139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# import time, math\n",
        "# def init_pytorch(shape, dtype=tf.float32, partition_info=None):\n",
        "#   fan = np.prod(shape[:-1])\n",
        "#   bound = 1 / math.sqrt(fan)\n",
        "#   return tf.random.uniform(shape, minval=-bound, maxval=bound, dtype=dtype)\n",
        "\n",
        "initializer = tf.keras.initializers.glorot_normal(seed=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0815 14:12:49.983681 140405211772800 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B41YNxNtCUwa",
        "colab": {}
      },
      "source": [
        "def ResNetBlock(input_layer, channels,stride=1):\n",
        "  \n",
        "  bn_1 = tf.keras.layers.BatchNormalization(momentum=0.9,epsilon=1e-5)(input_layer)\n",
        "  activation_layer_b1 = tf.keras.layers.Activation('relu')(bn_1)\n",
        "  if(stride==2):\n",
        "    block_layer_1 = tf.keras.layers.Conv2D(channels, (3,3) ,padding='same',kernel_initializer=initializer,use_bias=False)(activation_layer_b1)\n",
        "    block_layer_1= tf.keras.layers.MaxPooling2D()(block_layer_1)\n",
        "  else:\n",
        "    block_layer_1 = tf.keras.layers.Conv2D(channels, (3,3), padding='same',kernel_initializer=initializer,use_bias=False)(activation_layer_b1)\n",
        "  \n",
        "  bn_2 = tf.keras.layers.BatchNormalization(momentum=0.9,epsilon=1e-5)(block_layer_1)\n",
        "  activation_layer_b2 = tf.keras.layers.Activation('relu')(bn_2) \n",
        "  block_layer_2 = tf.keras.layers.Conv2D(channels, (3,3), padding='same',kernel_initializer=initializer,use_bias=False)(activation_layer_b2)\n",
        "   \n",
        "  \n",
        "  return block_layer_2\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7zl45v4UBTff",
        "colab": {}
      },
      "source": [
        "# from tf.keras.layers import Input, add, GlobalAveragePooling2D, Dense\n",
        "#from tf.keras.models import Model\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(32, 32, 3))\n",
        "\n",
        "x1 = tf.keras.layers.Conv2D(64, (3, 3),padding='same',kernel_initializer=initializer,use_bias=False)(inputs)   #32x32 \n",
        "activation_x1 = tf.keras.layers.Activation('relu')(x1)\n",
        "bn1 = tf.keras.layers.BatchNormalization(momentum=0.9,epsilon=1e-5)(activation_x1)\n",
        "\n",
        "# x2 = tf.keras.layers.Conv2D(64, (3, 3),padding='same',kernel_initializer=initializer)(bn1)   #32x32 \n",
        "# activation_x2 = tf.keras.layers.Activation('relu')(x2)\n",
        "# bn2 = tf.keras.layers.BatchNormalization(momentum=0.9,epsilon=1e-5)(activation_x2)\n",
        "\n",
        "# x3 = tf.keras.layers.Conv2D(64, (3, 3),padding='same')(activation_x2)   #32x32 \n",
        "# activation_x3 = tf.keras.layers.Activation('relu')(x3)\n",
        "# bn3 = tf.keras.layers.BatchNormalization(momentum=0.9,epsilon=1e-5)(activation_x3)\n",
        "\n",
        "# mx_p= tf.keras.layers.MaxPooling2D()(bn1)\n",
        "\n",
        "\n",
        "\n",
        "##block 1\n",
        "\n",
        "blk1 = ResNetBlock(bn1,64)  ##32x32\n",
        "z1 = tf.keras.layers.add([blk1,bn1])\n",
        "\n",
        "blk1_c = ResNetBlock(z1,64)\n",
        "z1_c = tf.keras.layers.add([blk1_c,z1])\n",
        "\n",
        "drp_1 = tf.keras.layers.SpatialDropout2D(0.1)(z1_c)\n",
        "\n",
        "\n",
        "##block 2\n",
        "\n",
        "blk2 = ResNetBlock(drp_1,128,stride=2)\n",
        "one_blk = tf.keras.layers.Conv2D(128, (1, 1), padding='same',strides=2)(drp_1)\n",
        "z2 = tf.keras.layers.add([blk2,one_blk])\n",
        "\n",
        "blk2_c = ResNetBlock(z2,128)\n",
        "z2_c = tf.keras.layers.add([blk2_c,z2])\n",
        "\n",
        "\n",
        "drp_2 = tf.keras.layers.SpatialDropout2D(0.1)(z2_c)\n",
        "\n",
        "##block3\n",
        "\n",
        "blk3 = ResNetBlock(drp_2,256,stride=2)\n",
        "one_blk_1 = tf.keras.layers.Conv2D(256, (1, 1), padding='same',strides=2)(drp_2)\n",
        "z3 = tf.keras.layers.add([blk3,one_blk_1])\n",
        "\n",
        "blk3_c = ResNetBlock(z3,256)\n",
        "z3_c = tf.keras.layers.add([blk3_c,z3])\n",
        "\n",
        "\n",
        "drp_3 = tf.keras.layers.Dropout(0.1)(z3_c)\n",
        "#block4\n",
        "\n",
        "blk4 = ResNetBlock(drp_3,256,stride=2)\n",
        "one_blk_2 = tf.keras.layers.Conv2D(256, (1, 1), padding='same',strides=2)(drp_3)\n",
        "z4 = tf.keras.layers.add([blk4,one_blk_2])\n",
        "\n",
        "blk4_c = ResNetBlock(z4,256)\n",
        "z4_c = tf.keras.layers.add([blk4_c,z4])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "avg_pool_layer = tf.keras.layers.GlobalAveragePooling2D()(z4_c)\n",
        "\n",
        "\n",
        "fc_layer = tf.keras.layers.Dense(10, activation='softmax',kernel_initializer=initializer)(avg_pool_layer)\n",
        "\n",
        "\n",
        "model = tf.keras.models.Model(inputs=inputs, outputs= fc_layer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sV-nVdlMDwva",
        "outputId": "1e579fa6-75b4-413c-ad2b-a67321c6fe7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 64)   1728        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 64)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 64)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 64)   36864       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 64)   256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 64)   36864       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 64)   0           conv2d_5[0][0]                   \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 64)   36864       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 64)   36864       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 64)   0           conv2d_7[0][0]                   \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d (SpatialDropo (None, 32, 32, 64)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 64)   256         spatial_dropout2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 128)  73728       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 16, 16, 128)  0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 128)  512         max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 128)  147456      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 128)  8320        spatial_dropout2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 128)  0           conv2d_9[0][0]                   \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 128)  512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 128)  147456      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 128)  512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 128)  147456      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 128)  0           conv2d_12[0][0]                  \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_1 (SpatialDro (None, 16, 16, 128)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 128)  512         spatial_dropout2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 256)  294912      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 256)    0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 8, 8, 256)    1024        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 8, 8, 256)    0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 256)    589824      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 256)    33024       spatial_dropout2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 8, 8, 256)    0           conv2d_14[0][0]                  \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 256)    1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 256)    0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 256)    589824      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 256)    1024        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 256)    0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 256)    589824      activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 8, 8, 256)    0           conv2d_17[0][0]                  \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 8, 8, 256)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 256)    1024        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 256)    0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 256)    589824      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 256)    0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 4, 4, 256)    1024        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 4, 4, 256)    0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 4, 4, 256)    589824      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 4, 4, 256)    65792       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 4, 4, 256)    0           conv2d_19[0][0]                  \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 4, 4, 256)    1024        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 4, 4, 256)    0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 4, 4, 256)    589824      activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 4, 4, 256)    1024        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 4, 4, 256)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 4, 4, 256)    589824      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 4, 4, 256)    0           conv2d_22[0][0]                  \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 256)          0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           2570        global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 5,209,418\n",
            "Trainable params: 5,204,042\n",
            "Non-trainable params: 5,376\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HDMPrA1Gj01s"
      },
      "source": [
        "#Best LR would be 0.01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-5l4Uuj2MLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for 24 epochs only\n",
        "\n",
        "# MAX_LR= 0.2\n",
        "# base_lr = 0.01\n",
        "# p = 0\n",
        "# def lr_func(epoch,lr):\n",
        "#   lr = base_lr\n",
        "#   #print(\"lwr\",tf.train.get_or_create_global_step())\n",
        "#   max_lr = MAX_LR\n",
        "#   print(\"p value \",p)\n",
        "#   if(p == 0):\n",
        "#     lr = base_lr\n",
        "#   elif(p>0 and p<5):\n",
        "#     lr += (max_lr-base_lr)*(p)/5\n",
        "#   else:\n",
        "#     lr = max_lr - (max_lr-base_lr)*(p-5)/18\n",
        "#   print(\"final lr \",round(lr,5))\n",
        "  \n",
        "#   p +=1\n",
        "#   return round(lr,5)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PjzOgXaWj_uE",
        "colab": {}
      },
      "source": [
        "opt = tf.keras.optimizers.SGD(momentum=0.9,nesterov=True)\n",
        "model.compile(optimizer=opt , loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kZvjcz46ICr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##previous approch ::\n",
        "\n",
        "# sequence = list(range(len(tmp_aug)))\n",
        "# #train_data = lambda t: print(t)\n",
        "# sess = tf.compat.v1.Session()\n",
        "# #train_data = lambda t: print(t)\n",
        "# train_data = lambda t : (np.concatenate((np.array(tmp_aug[t][0]),np.array(tmp_not_aug[t][0])),axis=0),\\\n",
        "#                        np.concatenate((np.array(tmp_aug[t][1]),np.array(tmp_not_aug[t][1])),axis=0))\n",
        "# #global_step = tf.train.get_or_create_global_step()\n",
        "# #i=0\n",
        "# #train_data_func = lambda: train_data(global_step)\n",
        "\n",
        "# train_data_f = list(map(train_data,sequence))\n",
        "# #test_data = lambda : test_generator.next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohvayfmZ1Nnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# newimage = np.zeros((512*98,32,32,3))\n",
        "# newlabel = np.zeros((512*98,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PBKCabd7BNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import h5py\n",
        "# with h5py.File('aug_img.hdf5', 'r') as f:\n",
        "#     data = list(f['dataset'])\n",
        "#     label = list(f['labels'])\n",
        "    \n",
        "# f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCMcOyj5cz-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = tf.keras.utils.HDF5Matrix('aug_img.hdf5','dataset')\n",
        "label = tf.keras.utils.HDF5Matrix('aug_img.hdf5','labels')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMpz9Oa8sQrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##from HDF5 ---\n",
        "import random\n",
        "\n",
        "train_data_aug_l = lambda i: (np.array(data[i:i+168]),np.array(label[i:i+168]))\n",
        "train_data_wo_l = lambda i: (np.array(train_features[i:i+168]),np.array(train_labels[i:i+168]))\n",
        "\n",
        "train_data_aug = lambda i: (np.array(data[i:i+256]),np.array(label[i:i+256]))\n",
        "train_data_wo = lambda i: (np.array(train_features[i:i+256]),np.array(train_labels[i:i+256]))\n",
        "\n",
        "num_seq = list(range(len(train_features)//512+1))\n",
        "\n",
        "\n",
        "def data_generator():\n",
        "  \n",
        "  train_data= np.zeros(shape=(50000,32,32,3))\n",
        "  train_lbl = np.zeros(shape=(50000,10))\n",
        "  \n",
        "  \n",
        "  tmp=0\n",
        "  for k in num_seq:\n",
        "    aug_ran = random.randrange(0,len(data)-256)\n",
        "    wo_aug = random.randrange(0,len(train_features)-256)\n",
        "\n",
        "    inital=tmp\n",
        "    if(k == 97):\n",
        "      final = inital+336\n",
        "      train_data[inital:final] = np.concatenate((train_data_aug_l(aug_ran)[0],train_data_wo_l(wo_aug)[0]),axis=0)\n",
        "      train_lbl[inital:final] = np.concatenate((train_data_aug_l(aug_ran)[1],train_data_wo_l(wo_aug)[1]),axis=0)\n",
        "    else:\n",
        "      final  = inital+512\n",
        "      train_data[inital:final] = np.concatenate((train_data_aug(aug_ran)[0],train_data_wo(wo_aug)[0]),axis=0)\n",
        "      train_lbl[inital:final] = np.concatenate((train_data_aug(aug_ran)[1],train_data_wo(wo_aug)[1]),axis=0)\n",
        "\n",
        "    tmp += 512\n",
        "  \n",
        "  return train_data,train_lbl\n",
        "  \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNoxs2zSTpUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x,y = data_generator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKx2xkNOTuZ0",
        "colab_type": "code",
        "outputId": "1d284822-0d39-4e5e-9cce-517da7ca2d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "plt.imshow(x[4634])\n",
        "y[4634]\n",
        "#x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0815 14:14:00.678377 140405211772800 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "upsNiPO4JWjb",
        "outputId": "7ba7a514-e008-4d0d-e6df-4b56d1c5a6a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "filepath = \"Resnet-13-test1.hdf5\"\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "tmp_gen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "##Train the model\n",
        "# model_info = model.fit_generator(train_generator,\n",
        "#                                  steps_per_epoch=np.ceil(50000/128), epochs=24,  \n",
        "#                                  validation_data = test_generator, verbose=1,callbacks=[checkpoint,LearningRateScheduler(lr_func, verbose=1)])\n",
        "\n",
        "MAX_LR= 0.15\n",
        "base_lr = 0.005\n",
        "EPOCHS=24\n",
        "for i in range(EPOCHS): \n",
        "  \n",
        "  def lr_func(epoch,lr):\n",
        "    lr = base_lr\n",
        "    #print(\"lwr\",tf.train.get_or_create_global_step())\n",
        "    max_lr = MAX_LR\n",
        "    \n",
        "    if(i == 0):\n",
        "      lr = base_lr\n",
        "    elif(i>0 and i<5):\n",
        "      lr += (max_lr-base_lr)*(i)/5\n",
        "    else:\n",
        "      lr = max_lr - (max_lr-base_lr)*(i-5)/18\n",
        "    print(\"final lr \",round(lr,5))\n",
        "\n",
        "    return round(lr,5)\n",
        "\n",
        "  \n",
        "\n",
        "for i in range(20):\n",
        "  \n",
        "  X_train,X_label = data_generator()\n",
        "  model.fit(tmp_gen.flow(X_train,X_label,batch_size=512),steps_per_epoch=np.ceil(50000/512),\n",
        "                               epochs=1,validation_data=test_generator)\n",
        "                         # callbacks=[LearningRateScheduler(lr_func, verbose=1)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 98s 1s/step - loss: 2.9418 - acc: 0.2472 - val_loss: 2.4038 - val_acc: 0.2862\n",
            "98/98 [==============================] - 86s 876ms/step - loss: 1.6334 - acc: 0.3958 - val_loss: 1.8181 - val_acc: 0.3905\n",
            "98/98 [==============================] - 86s 876ms/step - loss: 1.4598 - acc: 0.4644 - val_loss: 1.5969 - val_acc: 0.4544\n",
            "98/98 [==============================] - 86s 876ms/step - loss: 1.3127 - acc: 0.5245 - val_loss: 1.4899 - val_acc: 0.4995\n",
            "98/98 [==============================] - 86s 876ms/step - loss: 1.1779 - acc: 0.5778 - val_loss: 1.6016 - val_acc: 0.4844\n",
            "98/98 [==============================] - 86s 875ms/step - loss: 1.0692 - acc: 0.6158 - val_loss: 1.5167 - val_acc: 0.5287\n",
            "98/98 [==============================] - 86s 876ms/step - loss: 0.9810 - acc: 0.6502 - val_loss: 1.2447 - val_acc: 0.5800\n",
            "98/98 [==============================] - 86s 876ms/step - loss: 0.9037 - acc: 0.6790 - val_loss: 1.4962 - val_acc: 0.5489\n",
            "98/98 [==============================] - 86s 876ms/step - loss: 0.8100 - acc: 0.7111 - val_loss: 1.1308 - val_acc: 0.6339\n",
            "98/98 [==============================] - 86s 875ms/step - loss: 0.7591 - acc: 0.7302 - val_loss: 1.0852 - val_acc: 0.6390\n",
            "98/98 [==============================] - 86s 874ms/step - loss: 0.6993 - acc: 0.7523 - val_loss: 1.1398 - val_acc: 0.6471\n",
            "98/98 [==============================] - 86s 875ms/step - loss: 0.6576 - acc: 0.7682 - val_loss: 1.5308 - val_acc: 0.5950\n",
            "98/98 [==============================] - 86s 877ms/step - loss: 0.6057 - acc: 0.7867 - val_loss: 1.0184 - val_acc: 0.6908\n",
            "98/98 [==============================] - 86s 877ms/step - loss: 0.5645 - acc: 0.8008 - val_loss: 1.0934 - val_acc: 0.6653\n",
            "98/98 [==============================] - 86s 876ms/step - loss: 0.5342 - acc: 0.8121 - val_loss: 1.0403 - val_acc: 0.6851\n",
            "98/98 [==============================] - 86s 878ms/step - loss: 0.4942 - acc: 0.8270 - val_loss: 1.3838 - val_acc: 0.6249\n",
            "98/98 [==============================] - 86s 876ms/step - loss: 0.4569 - acc: 0.8408 - val_loss: 0.9658 - val_acc: 0.6977\n",
            "98/98 [==============================] - 86s 877ms/step - loss: 0.4364 - acc: 0.8483 - val_loss: 1.1442 - val_acc: 0.6836\n",
            "98/98 [==============================] - 86s 878ms/step - loss: 0.4071 - acc: 0.8581 - val_loss: 0.9900 - val_acc: 0.7103\n",
            "98/98 [==============================] - 86s 877ms/step - loss: 0.3836 - acc: 0.8663 - val_loss: 0.9514 - val_acc: 0.7106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cQmN6Lxeugu",
        "colab_type": "code",
        "outputId": "3ed7e259-a2d1-41fc-c732-3c3bfc8abfa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "plt.imshow(X_train[19])\n",
        "X_label[19]\n",
        "#class_names = ['airplane','automobile','bird','cat','deer',\n",
        " #              'dog','frog','horse','ship','truck']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0815 13:37:01.823027 140478476994432 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD1_C-6ufxyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMVf9mb2As40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "9"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}