{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-14- David",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEtVTK3uYk9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import time, math\n",
        "import cv2\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow.contrib.eager as tfe\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5mkJO53h-Zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.4 \n",
        "epochs = 25\n",
        "batch_size = 512\n",
        "end_percentage = 0.05\n",
        "triangle_tilt = 0.7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WR3LO8tidAc",
        "colab_type": "code",
        "outputId": "2734cb90-3a8f-449a-c2ca-f8ca8fb22108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Loading the CIFAR10 60000 Training and 10000 Test data into respective numpy arrays\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "n_train, n_test = X_train.shape[0], X_test.shape[0]\n",
        "img_size = X_train.shape[1]\n",
        "n_classes = y_train.max() + 1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJq-7uMpmU6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')/255\n",
        "X_test = X_test.astype('float32')/255\n",
        "Y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
        "Y_test = tf.keras.utils.to_categorical(y_test, n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6QYdPNtQ99J",
        "colab_type": "code",
        "outputId": "188db2f3-6ff1-4552-ef6a-f3679a2a842c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_mean = np.mean(X_train, axis=(0,1,2))\n",
        "X_train_std = np.std(X_train, axis=(0,1,2))\n",
        "print(X_train_mean, X_train_std)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.4914009  0.48215896 0.4465308 ] [0.24703279 0.24348423 0.26158753]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzRLfIA8Q-xx",
        "colab_type": "code",
        "outputId": "aabf3183-d66f-4f50-bf44-d77f86b1fbb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test_mean = np.mean(X_test, axis=(0,1,2))\n",
        "X_test_std = np.std(X_test, axis=(0,1,2))\n",
        "print(X_test_mean, X_test_std)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.49421427 0.4851322  0.45040992] [0.24665268 0.24289216 0.2615922 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOh0j981RHnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = (X_train - X_train_mean) / X_train_std\n",
        "X_test = (X_test - X_test_mean) / X_test_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2smHikv8OChz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7S_Eg5lODYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(validation_iterator, test_y, model):\n",
        "    result = model.evaluate_generator(validation_iterator, steps = len(validation_iterator))\n",
        "    predicted_class = np.argmax(result, axis=1)\n",
        "    true_class = np.argmax(test_y, axis=1)\n",
        "    num_correct = np.sum(predicted_class == true_class) \n",
        "    accuracy = float(num_correct)/result.shape[0]\n",
        "    return (accuracy * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMpsqn_O0CvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_examples(X,y,classes):\n",
        "    rows = int(np.ceil(len(X)/5))\n",
        "    if X.shape[1] > 64:\n",
        "        multiplier = 2\n",
        "    else:\n",
        "        multiplier = 1\n",
        "    fig = plt.figure(figsize=(10*multiplier, rows*2*multiplier))\n",
        "    for idx in np.arange(len(X)):\n",
        "        img = X[idx]\n",
        "        assert (len(img.shape)==3 and img.shape[2] in [1,3,4]) or len(img.shape)==2\n",
        "        ax = fig.add_subplot(rows, 5, idx + 1, xticks=[], yticks=[])\n",
        "        cmap = None\n",
        "        if (len(img.shape)==3 and img.shape[2]==1) or len(img.shape)==2:\n",
        "            cmap=\"binary\"\n",
        "        if len(img.shape)==3 and img.shape[2]==1:\n",
        "            img = img.reshape((img.shape[0],img.shape[1]))\n",
        "        ax.imshow(img,cmap=cmap)\n",
        "        ax.set_title(classes[np.argmax(y[idx])])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFJt6i8e0IzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cifar10_labels():\n",
        "    return ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMBWETcC0wi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def min_max_scale(X):\n",
        "  return (X - np.min(X))/(np.max(X)-np.min(X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDK_7gDlHEFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cutout_eraser_and_padcrop(p=0.5, s_l=0.25, s_h=0.25, r_1=0.3, r_2=1 / 0.3, max_erasures_per_image=1, pixel_level=True, random_crop_size=(32, 32), padding_pixels=4):\n",
        "    \"\"\"\n",
        "    :param p:\n",
        "    :param s_l: Minimum Area Proportion of Original that may be cut\n",
        "    :param s_h: Maximum Area Proportion of Original that may be cut\n",
        "    :param r_1: Min Aspect Ratio\n",
        "    :param r_2: Max Aspect Ratio\n",
        "    :param max_erasures_per_image:\n",
        "    :param pixel_level:\n",
        "    :return: Eraser to be used as Preprocessing Function\n",
        "    \"\"\"\n",
        "    assert max_erasures_per_image >= 1\n",
        "\n",
        "    def eraser(input_img):\n",
        "        v_l = np.min(input_img)\n",
        "        v_h = np.max(input_img)\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        mx = np.random.randint(1, max_erasures_per_image + 1)\n",
        "        # print(\"Erasures = \",mx,end =\", \")\n",
        "        for i in range(mx):\n",
        "            while True:\n",
        "                s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "                r = np.random.uniform(r_1, r_2)\n",
        "                w = int(np.sqrt(s / r))\n",
        "                h = int(np.sqrt(s * r))\n",
        "                left = np.random.randint(0, img_w)\n",
        "                top = np.random.randint(0, img_h)\n",
        "\n",
        "                if left + w <= img_w and top + h <= img_h:\n",
        "                    break\n",
        "\n",
        "            # print(\"W = \",w,\"H = \",h,end =\", \")\n",
        "\n",
        "            if pixel_level:\n",
        "                # print(np.max(img_c),np.min(img_c),v_l,v_h)\n",
        "                c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "                # print(c.shape,np.min(c),np.max(c),np.median(c))\n",
        "            else:\n",
        "                c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "            input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        # print()\n",
        "        return input_img\n",
        "     \n",
        "    def random_crop(input_image):\n",
        "          # Note: image_data_format is 'channel_last'\n",
        "          assert input_image.shape[2] == 3\n",
        "          \n",
        "          #Pad by 4 pixels\n",
        "          img = cv2.copyMakeBorder(input_image, padding_pixels, padding_pixels, padding_pixels, padding_pixels, cv2.BORDER_REPLICATE)\n",
        "          \n",
        "          height, width = img.shape[0], img.shape[1]\n",
        "          dy, dx = random_crop_size\n",
        "          x = np.random.randint(0, width - dx + 1)\n",
        "          y = np.random.randint(0, height - dy + 1)\n",
        "          return img[y:(y+dy), x:(x+dx), :]\n",
        "        \n",
        "    def preproc_image(input_image):\n",
        "      #return eraser\n",
        "      return eraser(random_crop(input_image))\n",
        "\n",
        "    return preproc_image\n",
        "      \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBPdtlO75o2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "   #featurewise_center=True,\n",
        "   #featurewise_std_normalization=True,\n",
        "   horizontal_flip=0.5,             # randomly flip images                                     \n",
        "   preprocessing_function=get_cutout_eraser_and_padcrop(p=0.5, s_l=0.2, s_h=0.2, r_1=0.2, r_2=1 / 0.3, max_erasures_per_image=1, pixel_level=False))\n",
        "\n",
        "_ = datagen.fit(X_train)\n",
        "train_iterator = datagen.flow(X_train, Y_train, batch_size=256, shuffle=False)\n",
        "\n",
        "# X_e, Y_e = train_iterator.next()\n",
        "# X_e = min_max_scale(X_e)\n",
        "# show_examples(X_e[0:10], Y_e[0:10], classes = get_cifar10_labels())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxc5QhiQR1X6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen_validation = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "datagen_validation.fit(X_test)\n",
        "validation_iterator = datagen_validation.flow(X_test, Y_test, batch_size=512, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTsgIk47GDWb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46436193-3c05-466c-a533-f021ce5cecd8"
      },
      "source": [
        "import h5py\n",
        "f = h5py.File('aug_img.hdf5', 'w')\n",
        "d = f.create_dataset('dataset', (1200000,32,32,3),chunks=(256,32,32,3))\n",
        "l = f.create_dataset('labels',(1200000,10),chunks=(256,10))\n",
        "\n",
        "\n",
        "batch_size=256\n",
        "EPOCHS =24\n",
        "aug_lbl=[]\n",
        "tmp=0\n",
        "for i in range(EPOCHS):\n",
        "  print(\"tmp \", tmp)\n",
        "  for j in range(len(train_iterator)):\n",
        "    initial = j*batch_size+tmp\n",
        "    train_gen = train_iterator.next()\n",
        "    if(j == 195 ):\n",
        "      final += 80\n",
        "      d[initial:final]= train_gen[0]\n",
        "      l[initial:final]= train_gen[1]\n",
        "      continue \n",
        "      \n",
        "    \n",
        "    final = initial + 256\n",
        "    d[initial:final]= train_gen[0]\n",
        "    l[initial:final]= train_gen[1]\n",
        "  \n",
        "  tmp = final\n",
        "\n",
        "# f.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tmp  0\n",
            "tmp  50000\n",
            "tmp  100000\n",
            "tmp  150000\n",
            "tmp  200000\n",
            "tmp  250000\n",
            "tmp  300000\n",
            "tmp  350000\n",
            "tmp  400000\n",
            "tmp  450000\n",
            "tmp  500000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10HGAQbDDg6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape=(32, 32, 3)\n",
        "num_outputs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37S1oFpA2wUJ",
        "colab_type": "code",
        "outputId": "dca25d8a-6bdc-4c91-df6b-e45972e0c8b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "#Define DawnNet model\n",
        "input = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "prep = tf.keras.layers.Conv2D(filters=32,\n",
        "                          kernel_size=(3, 3),\n",
        "                          strides=(1, 1),\n",
        "                          padding=\"same\",\n",
        "                          #kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.001))(input)\n",
        "prep = tf.keras.layers.BatchNormalization(axis=3,momentum=0.9, epsilon=1e-5)(prep)\n",
        "prep = tf.keras.layers.Activation(\"relu\")(prep)\n",
        "\n",
        "drp_1 = tf.keras.layers.SpatialDropout2D(0.001)(prep)\n",
        "layer1 = tf.keras.layers.Conv2D(filters=64,\n",
        "                          kernel_size=(3, 3),\n",
        "                          strides=(1, 1),\n",
        "                          padding=\"same\",\n",
        "                          #kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.001))(drp_1)\n",
        "layer1 = tf.keras.layers.BatchNormalization(axis=3,momentum=0.9, epsilon=1e-5)(layer1)\n",
        "layer1 = tf.keras.layers.Activation(\"relu\")(layer1)\n",
        "layer1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")(layer1)\n",
        "\n",
        "layer1_res1_identity = tf.keras.layers.Conv2D(filters=32,\n",
        "                          kernel_size=(1, 1),\n",
        "                          strides=(1, 1),\n",
        "                          padding=\"same\",\n",
        "                          #kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.0001))(layer1)\n",
        "layer1_res1 = tf.keras.layers.Conv2D(filters=64,\n",
        "                          kernel_size=(3, 3),\n",
        "                          strides=(1, 1),\n",
        "                          padding=\"same\",\n",
        "                          #kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.001))(layer1_res1_identity)\n",
        "layer1_res1 = tf.keras.layers.BatchNormalization(axis=3,momentum=0.9, epsilon=1e-5)(layer1_res1)\n",
        "layer1_res1 = tf.keras.layers.Activation(\"relu\")(layer1_res1)\n",
        "\n",
        "\n",
        "drp_2 = tf.keras.layers.SpatialDropout2D(0.001)(layer1_res1)\n",
        "\n",
        "#concat1 = tf.keras.layers.concatenate([layer1, layer1_res1])\n",
        "\n",
        "layer1_res2 = tf.keras.layers.Conv2D(filters=64,\n",
        "                          kernel_size=(3, 3),\n",
        "                          strides=(1, 1),\n",
        "                          padding=\"same\",\n",
        "                          #kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.001))(drp_2)\n",
        "layer1_res2 = tf.keras.layers.BatchNormalization(axis=3,momentum=0.9, epsilon=1e-5)(layer1_res2)\n",
        "layer1_res2 = tf.keras.layers.Activation(\"relu\")(layer1_res2)\n",
        "\n",
        "concat1 = tf.keras.layers.concatenate([layer1, layer1_res2])\n",
        "\n",
        "\n",
        "layer2 = tf.keras.layers.Conv2D(filters=128,\n",
        "                          kernel_size=(3, 3),\n",
        "                          strides=(1, 1),\n",
        "                          padding=\"same\",\n",
        "                          #kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.001))(concat1)\n",
        "layer2 = tf.keras.layers.BatchNormalization(axis=3,momentum=0.9, epsilon=1e-5)(layer2)\n",
        "layer2 = tf.keras.layers.Activation(\"relu\")(layer2)\n",
        "layer2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")(layer2)\n",
        "\n",
        "drp_3 = tf.keras.layers.SpatialDropout2D(0.001)(layer2)\n",
        "\n",
        "\n",
        "layer3 = tf.keras.layers.Conv2D(filters=256,\n",
        "                          kernel_size=(3, 3),\n",
        "                          strides=(1, 1),\n",
        "                          padding=\"same\",\n",
        "                          #kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.001))(drp_3)\n",
        "layer3 = tf.keras.layers.BatchNormalization(axis=3,momentum=0.9, epsilon=1e-5)(layer3)\n",
        "layer3 = tf.keras.layers.Activation(\"relu\")(layer3)\n",
        "layer3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")(layer3)\n",
        "\n",
        "drp_3 = tf.keras.layers.SpatialDropout2D(0.001)(layer3)\n",
        "\n",
        "layer3_res1_identity = tf.keras.layers.Conv2D(filters=128,\n",
        "                          kernel_size=(1, 1),\n",
        "                          strides=(1, 1),\n",
        "                          padding=\"same\",\n",
        "                          #kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.001))(drp_3)\n",
        "layer3_res1 = tf.keras.layers.Conv2D(filters=256,\n",
        "                          kernel_size=(3, 3),\n",
        "                          strides=(1, 1),\n",
        "                          padding=\"same\",\n",
        "                          #kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.001))(layer3_res1_identity)\n",
        "layer3_res1 = tf.keras.layers.BatchNormalization(axis=3,momentum=0.9, epsilon=1e-5)(layer3_res1)\n",
        "layer3_res1 = tf.keras.layers.Activation(\"relu\")(layer3_res1)\n",
        "\n",
        "layer3_res2 = tf.keras.layers.Conv2D(filters=256,\n",
        "                          kernel_size=(3, 3),\n",
        "                          strides=(1, 1),\n",
        "                          padding=\"same\",\n",
        "                          #kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.001))(layer3_res1)\n",
        "layer3_res2 = tf.keras.layers.BatchNormalization(axis=3,momentum=0.9, epsilon=1e-5)(layer3_res2)\n",
        "layer3_res2 = tf.keras.layers.Activation(\"relu\")(layer3_res2)\n",
        "\n",
        "\n",
        "\n",
        "concat2 = tf.keras.layers.concatenate([drp_3, layer3_res2])\n",
        "\n",
        "gmp = tf.keras.layers.GlobalMaxPooling2D()(concat2)\n",
        "dense = tf.keras.layers.Dense(units=num_outputs, activation=\"softmax\")(gmp) #kernel_initializer=\"he_normal\", \n",
        "\n",
        "model = tf.keras.models.Model(inputs=input, outputs=dense)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0817 11:11:34.938884 139723697670016 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRKvgcZrFgIj",
        "colab_type": "code",
        "outputId": "24f1cf3d-8b9e-423e-b6a1-0bad86b6344e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d (SpatialDropo (None, 32, 32, 32)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 64)   18496       spatial_dropout2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 16, 16, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 16, 16, 32)   2080        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 16, 16, 64)   18496       conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 16, 16, 64)   256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 16, 16, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_1 (SpatialDro (None, 16, 16, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 16, 16, 64)   36928       spatial_dropout2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 16, 16, 64)   256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 16, 16, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 16, 16, 128)  0           max_pooling2d[0][0]              \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 128)  147584      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 16, 16, 128)  512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 16, 16, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 128)    0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_2 (SpatialDro (None, 8, 8, 128)    0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 8, 8, 256)    295168      spatial_dropout2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 8, 8, 256)    1024        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 8, 8, 256)    0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 256)    0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_3 (SpatialDro (None, 4, 4, 256)    0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 4, 4, 128)    32896       spatial_dropout2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 4, 4, 256)    295168      conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 4, 4, 256)    1024        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 4, 4, 256)    0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 4, 4, 256)    590080      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 4, 4, 256)    1024        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 4, 4, 256)    0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 4, 4, 512)    0           spatial_dropout2d_3[0][0]        \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d (GlobalMax (None, 512)          0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           5130        global_max_pooling2d[0][0]       \n",
            "==================================================================================================\n",
            "Total params: 1,447,402\n",
            "Trainable params: 1,445,162\n",
            "Non-trainable params: 2,240\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suxU4w1SF6EX",
        "colab_type": "code",
        "outputId": "b6cc64ff-3a72-4d54-81d4-8c1df41cd9d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "def min_max_scaler(iterations, num_iterations, end_percentage, min_val, max_val, invert = False, triangle_tilt = 0.65):\n",
        "  non_slant_mid_cycle_id = int(num_iterations * ((1. - end_percentage)) / float(2))\n",
        "  mid_cycle_id = int(triangle_tilt*int(num_iterations * ((1. - end_percentage)) / float(2)))\n",
        "  value = 0\n",
        "  if iterations > 2 * non_slant_mid_cycle_id:\n",
        "    \n",
        "    \n",
        "      extra_iters = (iterations - 2 * non_slant_mid_cycle_id)\n",
        "      current_percentage = 1 - (1 - 1/10)*extra_iters/(num_iterations - 2 * non_slant_mid_cycle_id)\n",
        "            \n",
        "\n",
        "  elif iterations >  mid_cycle_id:\n",
        "      current_percentage = 1. - (iterations - mid_cycle_id) / (2*non_slant_mid_cycle_id - mid_cycle_id)\n",
        "      \n",
        "  else:\n",
        "      current_percentage = iterations / mid_cycle_id\n",
        "      \n",
        "  if invert:\n",
        "    if iterations > 2 * non_slant_mid_cycle_id:\n",
        "      return max_val\n",
        "    return max_val - current_percentage * (max_val - min_val)\n",
        "  else:\n",
        "    if iterations > 2 * non_slant_mid_cycle_id:\n",
        "      return min_val * current_percentage\n",
        "    return min_val + current_percentage * (max_val - min_val)\n",
        "  \n",
        "    \n",
        "\n",
        "print(\"=\"*80)\n",
        "scales = []\n",
        "for i in range(1000):\n",
        "  p = min_max_scaler(i,1000,0.1,min_val=0.1,max_val=1, invert=False)\n",
        "  scales.append(p)\n",
        "  \n",
        "plt.plot(np.array(scales))\n",
        "plt.title(\"LR Graph\")\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_zaj292F7PD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    AveragePooling2D\n",
        ")\n",
        "\n",
        "\n",
        "# Code is ported from https://github.com/fastai/fastai\n",
        "class OneCycleLR(Callback):\n",
        "    def __init__(self,\n",
        "                 epochs,\n",
        "                 batch_size,\n",
        "                 samples,\n",
        "                 steps,\n",
        "                 max_lr,\n",
        "                 end_percentage=0.1,\n",
        "                 scale=100,\n",
        "                 maximum_momentum=0.95,\n",
        "                 minimum_momentum=0.85,\n",
        "                 triangle_tilt = 0.75,\n",
        "                 verbose=True):\n",
        "        \"\"\" This callback implements a cyclical learning rate policy (CLR).\n",
        "        This is a special case of Cyclic Learning Rates, where we have only 1 cycle.\n",
        "        After the completion of 1 cycle, the learning rate will decrease rapidly to\n",
        "        100th its initial lowest value.\n",
        "        # Arguments:\n",
        "            max_lr: Float. Initial learning rate. This also sets the\n",
        "                starting learning rate (which will be 10x smaller than\n",
        "                this), and will increase to this value during the first cycle.\n",
        "            end_percentage: Float. The percentage of all the epochs of training\n",
        "                that will be dedicated to sharply decreasing the learning\n",
        "                rate after the completion of 1 cycle. Must be between 0 and 1.\n",
        "            scale_percentage: Float or None. If float, must be between 0 and 1.\n",
        "                If None, it will compute the scale_percentage automatically\n",
        "                based on the `end_percentage`.\n",
        "            maximum_momentum: Optional. Sets the maximum momentum (initial)\n",
        "                value, which gradually drops to its lowest value in half-cycle,\n",
        "                then gradually increases again to stay constant at this max value.\n",
        "                Can only be used with SGD Optimizer.\n",
        "            minimum_momentum: Optional. Sets the minimum momentum at the end of\n",
        "                the half-cycle. Can only be used with SGD Optimizer.\n",
        "            verbose: Bool. Whether to print the current learning rate after every\n",
        "                epoch.\n",
        "        # Reference\n",
        "            - [A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, weight_decay, and weight decay](https://arxiv.org/abs/1803.09820)\n",
        "            - [Super-Convergence: Very Fast Training of Residual Networks Using Large Learning Rates](https://arxiv.org/abs/1708.07120)\n",
        "        \"\"\"\n",
        "        super(OneCycleLR, self).__init__()\n",
        "\n",
        "        if end_percentage < 0. or end_percentage > 1.:\n",
        "            raise ValueError(\"`end_percentage` must be between 0 and 1\")\n",
        "\n",
        "\n",
        "        self.initial_lr = max_lr\n",
        "        self.end_percentage = end_percentage\n",
        "        self.scale = scale\n",
        "        self.max_momentum = maximum_momentum\n",
        "        self.min_momentum = minimum_momentum\n",
        "        self.verbose = verbose\n",
        "\n",
        "        if self.max_momentum is not None and self.min_momentum is not None:\n",
        "            self._update_momentum = True\n",
        "        else:\n",
        "            self._update_momentum = False\n",
        "\n",
        "        self.clr_iterations = 0.\n",
        "        self.history = {}\n",
        "\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.samples = samples\n",
        "        self.steps = steps\n",
        "        self.num_iterations = None\n",
        "        self.mid_cycle_id = None\n",
        "\n",
        "    def _reset(self):\n",
        "        \"\"\"\n",
        "        Reset the callback.\n",
        "        \"\"\"\n",
        "        self.clr_iterations = 0.\n",
        "        self.history = {}\n",
        "\n",
        "    def compute_lr(self):\n",
        "        \"\"\"\n",
        "        Compute the learning rate based on which phase of the cycle it is in.\n",
        "        - If in the first half of training, the learning rate gradually increases.\n",
        "        - If in the second half of training, the learning rate gradually decreases.\n",
        "        - If in the final `end_percentage` portion of training, the learning rate\n",
        "            is quickly reduced to near 100th of the original min learning rate.\n",
        "        # Returns:\n",
        "            the new learning rate\n",
        "        \"\"\"\n",
        "        new_lr = min_max_scaler(self.clr_iterations, self.num_iterations, self.end_percentage, self.initial_lr/self.scale, self.initial_lr, invert = False, triangle_tilt=triangle_tilt)\n",
        "        return new_lr\n",
        "\n",
        "    def compute_momentum(self):\n",
        "        \"\"\"\n",
        "         Compute the momentum based on which phase of the cycle it is in.\n",
        "        - If in the first half of training, the momentum gradually decreases.\n",
        "        - If in the second half of training, the momentum gradually increases.\n",
        "        - If in the final `end_percentage` portion of training, the momentum value\n",
        "            is kept constant at the maximum initial value.\n",
        "        # Returns:\n",
        "            the new momentum value\n",
        "        \"\"\"    \n",
        "        new_momentum = min_max_scaler(self.clr_iterations, self.num_iterations, self.end_percentage, self.min_momentum, self.max_momentum, invert = True, triangle_tilt=triangle_tilt)\n",
        "        return new_momentum\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.steps is not None:\n",
        "            self.num_iterations = self.epochs * self.steps\n",
        "        else:\n",
        "            if (self.samples % self.batch_size) == 0:\n",
        "                remainder = 0\n",
        "            else:\n",
        "                remainder = 1\n",
        "            self.num_iterations = (self.epochs + remainder) * self.samples // self.batch_size\n",
        "\n",
        "        self.mid_cycle_id = int(self.num_iterations * ((1. - self.end_percentage)) / float(2))\n",
        "\n",
        "        self._reset()\n",
        "        K.set_value(self.model.optimizer.lr, self.compute_lr())\n",
        "\n",
        "        if self._update_momentum:\n",
        "            if not hasattr(self.model.optimizer, 'momentum'):\n",
        "                raise ValueError(\"Momentum can be updated only on SGD optimizer !\")\n",
        "\n",
        "            new_momentum = self.compute_momentum()\n",
        "            K.set_value(self.model.optimizer.momentum, new_momentum)\n",
        "\n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "\n",
        "        self.clr_iterations += 1\n",
        "        new_lr = self.compute_lr()\n",
        "\n",
        "        self.history.setdefault('lr', []).append(\n",
        "            K.get_value(self.model.optimizer.lr))\n",
        "        K.set_value(self.model.optimizer.lr, new_lr)\n",
        "\n",
        "        if self._update_momentum:\n",
        "            if not hasattr(self.model.optimizer, 'momentum'):\n",
        "                raise ValueError(\"Momentum can be updated only on SGD optimizer !\")\n",
        "\n",
        "            new_momentum = self.compute_momentum()\n",
        "\n",
        "            self.history.setdefault('momentum', []).append(\n",
        "                K.get_value(self.model.optimizer.momentum))\n",
        "            K.set_value(self.model.optimizer.momentum, new_momentum)\n",
        "\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if self.verbose:\n",
        "            if self._update_momentum:\n",
        "                print(\" - lr: %0.5f - momentum: %0.2f \" %\n",
        "                      (self.history['lr'][-1], self.history['momentum'][-1]))\n",
        "\n",
        "            else:\n",
        "                print(\" - lr: %0.5f \" % (self.history['lr'][-1]))\n",
        "                \n",
        "    \n",
        "    def plot(self):\n",
        "        plt.title(\"LR-Plot\")\n",
        "        plt.plot(self.history['lr'])\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"LR\")\n",
        "        plt.show()\n",
        "        \n",
        "        plt.title(\"Momentum-Plot\")\n",
        "        plt.plot(self.history['momentum'])\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"Momentum\")\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_e-8-U1IRRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StopAtAccValue(Callback):\n",
        "  def __init__(self,validation_iterator, threshold = 0.9, ):\n",
        "    super(StopAtAccValue, self).__init__()\n",
        "    self.threshold = threshold\n",
        "    self.validation_iterator = validation_iterator\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    score = self.model.evaluate_generator(self.validation_iterator,steps=len(self.validation_iterator))\n",
        "    acc = score[1]\n",
        "    if acc >= self.threshold:\n",
        "      self.model.stop_training = True\n",
        "      print(\"Stopping Training:: Val Acc = %.3f Achieved\"%(acc))\n",
        "    else:\n",
        "      print(\"Continue Training:: Val Acc = %.3f, Threshold = %.3f\"%(acc,self.threshold))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NblM6VSGBNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "olr = OneCycleLR(epochs=epochs, batch_size = batch_size,steps=len(train_iterator), \n",
        "                 samples=X_train.shape[0], max_lr=learning_rate, verbose = True, scale = 50, end_percentage=end_percentage,\n",
        "                 maximum_momentum = 0.95, minimum_momentum=0.85, triangle_tilt=triangle_tilt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWaEbb0BlBK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = tf.keras.optimizers.SGD(lr=0.0018, decay=5e-4, momentum=0.9, nesterov=True)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EecCH-q0Ege3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specifying the path to store the weights\n",
        "#filepath=\"/content/gdrive/My Drive/Assignment13_v3.4.hdf5\"\n",
        "filepath = \"/content/model.hdf5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=True, mode='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M47dMHTIU7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopper = StopAtAccValue(validation_iterator, threshold = 0.94)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSTRlAv4KUuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [olr]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD7GmQEYHaN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = tf.keras.utils.HDF5Matrix('./aug_img.hdf5','dataset')\n",
        "label = tf.keras.utils.HDF5Matrix('./aug_img.hdf5','labels')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waM9IronHO4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c496a667-912c-4f69-d8bb-48800f6d353f"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import random\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, data, label, train_features,train_labels, batch_size=32, dim=(32,32), n_channels=3,\n",
        "                 n_classes=10, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.label = label\n",
        "        self.data = data\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.train_features = train_features\n",
        "        self.train_labels = train_labels\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.data) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        \n",
        "        # Generate indexes of the batch\n",
        "        #indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        aug_ran = random.randrange(0,len(self.data)-256)\n",
        "        wo_aug = random.randrange(0,len(self.train_features)-256)\n",
        "        #print(aug_ran)\n",
        "        train_data_aug = lambda i: (np.array(self.data[i:i+256]),np.array(self.label[i:i+256]))\n",
        "        train_data_wo = lambda i: (np.array(self.train_features[i:i+256]),np.array(self.train_labels[i:i+256]))\n",
        "        \n",
        "        \n",
        "        X = np.concatenate((train_data_aug(aug_ran)[0],train_data_wo(wo_aug)[0]),axis=0)\n",
        "        y = np.concatenate((train_data_aug(aug_ran)[1],train_data_wo(wo_aug)[1]),axis=0)\n",
        "        #print(\"label\",y.shape, \" \" ,X.shape)\n",
        "        #plt.imshow(X[0])\n",
        "        # Generate data\n",
        "        #X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.data))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "            \n",
        "gen = DataGenerator(data,label,X_train,Y_train,512)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gEHda17HoWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaDjaDz3szBx",
        "colab_type": "code",
        "outputId": "569409b2-ab4a-4f94-a18d-d2e6cc87b45f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "\n",
        "# model_info = model.fit_generator(gen,\n",
        "#                                  steps_per_epoch = len(train_iterator), epochs = epochs, \n",
        "#                                  validation_data = validation_iterator, \n",
        "#                                  validation_steps = len(validation_iterator),\n",
        "#                                  verbose=2, callbacks=callbacks)\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
        "model.fit_generator(generator=gen,steps_per_epoch=np.ceil(50000/512), epochs=24,  \n",
        "                                validation_data = validation_iterator, verbose=1,callbacks =[olr])\n",
        "end = time.time()\n",
        "# print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "# # plot model history\n",
        "# plot_model_history(model_info)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 3.0995 - acc: 0.3994 - lr: 0.03136 - momentum: 0.94 \n",
            "98/98 [==============================] - 31s 316ms/step - loss: 3.0939 - acc: 0.4000 - val_loss: 2.3996 - val_acc: 0.5033\n",
            "Epoch 2/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 2.1861 - acc: 0.5743 - lr: 0.05495 - momentum: 0.94 \n",
            "98/98 [==============================] - 24s 249ms/step - loss: 2.1839 - acc: 0.5747 - val_loss: 2.4622 - val_acc: 0.5284\n",
            "Epoch 3/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 1.6784 - acc: 0.6859 - lr: 0.07855 - momentum: 0.93 \n",
            "98/98 [==============================] - 24s 249ms/step - loss: 1.6790 - acc: 0.6857 - val_loss: 1.5243 - val_acc: 0.7043\n",
            "Epoch 4/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 1.3538 - acc: 0.7444 - lr: 0.10215 - momentum: 0.93 \n",
            "98/98 [==============================] - 25s 251ms/step - loss: 1.3525 - acc: 0.7445 - val_loss: 1.2991 - val_acc: 0.7333\n",
            "Epoch 5/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 1.1392 - acc: 0.7812 - lr: 0.12574 - momentum: 0.92 \n",
            "98/98 [==============================] - 25s 250ms/step - loss: 1.1381 - acc: 0.7814 - val_loss: 1.2949 - val_acc: 0.7275\n",
            "Epoch 6/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 1.0335 - acc: 0.7946 - lr: 0.14934 - momentum: 0.91 \n",
            "98/98 [==============================] - 24s 250ms/step - loss: 1.0319 - acc: 0.7950 - val_loss: 1.1395 - val_acc: 0.7598\n",
            "Epoch 7/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.9317 - acc: 0.8133 - lr: 0.17294 - momentum: 0.91 \n",
            "98/98 [==============================] - 25s 250ms/step - loss: 0.9316 - acc: 0.8133 - val_loss: 1.0201 - val_acc: 0.7981\n",
            "Epoch 8/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.8917 - acc: 0.8235 - lr: 0.19654 - momentum: 0.90 \n",
            "98/98 [==============================] - 25s 250ms/step - loss: 0.8917 - acc: 0.8236 - val_loss: 1.0308 - val_acc: 0.7719\n",
            "Epoch 9/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.8452 - acc: 0.8372 - lr: 0.22013 - momentum: 0.90 \n",
            "98/98 [==============================] - 24s 250ms/step - loss: 0.8451 - acc: 0.8372 - val_loss: 1.2698 - val_acc: 0.7271\n",
            "Epoch 10/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.8402 - acc: 0.8369 - lr: 0.24373 - momentum: 0.89 \n",
            "98/98 [==============================] - 25s 251ms/step - loss: 0.8404 - acc: 0.8367 - val_loss: 0.9550 - val_acc: 0.8080\n",
            "Epoch 11/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.8201 - acc: 0.8444 - lr: 0.26733 - momentum: 0.88 \n",
            "98/98 [==============================] - 25s 251ms/step - loss: 0.8201 - acc: 0.8443 - val_loss: 1.0846 - val_acc: 0.7688\n",
            "Epoch 12/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.8257 - acc: 0.8447 - lr: 0.29092 - momentum: 0.88 \n",
            "98/98 [==============================] - 24s 250ms/step - loss: 0.8254 - acc: 0.8448 - val_loss: 0.9352 - val_acc: 0.8106\n",
            "Epoch 13/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.8267 - acc: 0.8446 - lr: 0.31452 - momentum: 0.87 \n",
            "98/98 [==============================] - 25s 251ms/step - loss: 0.8258 - acc: 0.8448 - val_loss: 1.0175 - val_acc: 0.7939\n",
            "Epoch 14/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.8154 - acc: 0.8538 - lr: 0.33812 - momentum: 0.87 \n",
            "98/98 [==============================] - 24s 249ms/step - loss: 0.8151 - acc: 0.8538 - val_loss: 0.8768 - val_acc: 0.8374\n",
            "Epoch 15/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.7978 - acc: 0.8603 - lr: 0.36171 - momentum: 0.86 \n",
            "98/98 [==============================] - 24s 250ms/step - loss: 0.7965 - acc: 0.8609 - val_loss: 1.0267 - val_acc: 0.7881\n",
            "Epoch 16/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.8022 - acc: 0.8586 - lr: 0.38531 - momentum: 0.85 \n",
            "98/98 [==============================] - 25s 250ms/step - loss: 0.8013 - acc: 0.8588 - val_loss: 0.9206 - val_acc: 0.8271\n",
            "Epoch 17/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.8080 - acc: 0.8591 - lr: 0.39521 - momentum: 0.85 \n",
            "98/98 [==============================] - 24s 249ms/step - loss: 0.8080 - acc: 0.8592 - val_loss: 0.9837 - val_acc: 0.7953\n",
            "Epoch 18/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.7776 - acc: 0.8674 - lr: 0.38251 - momentum: 0.85 \n",
            "98/98 [==============================] - 24s 250ms/step - loss: 0.7774 - acc: 0.8675 - val_loss: 1.0108 - val_acc: 0.7905\n",
            "Epoch 19/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.7717 - acc: 0.8692 - lr: 0.36982 - momentum: 0.86 \n",
            "98/98 [==============================] - 24s 250ms/step - loss: 0.7708 - acc: 0.8695 - val_loss: 0.8582 - val_acc: 0.8429\n",
            "Epoch 20/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.7329 - acc: 0.8818 - lr: 0.35712 - momentum: 0.86 \n",
            "98/98 [==============================] - 24s 250ms/step - loss: 0.7333 - acc: 0.8818 - val_loss: 0.8954 - val_acc: 0.8270\n",
            "Epoch 21/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.7430 - acc: 0.8774 - lr: 0.34443 - momentum: 0.86 \n",
            "98/98 [==============================] - 24s 250ms/step - loss: 0.7442 - acc: 0.8770 - val_loss: 0.8799 - val_acc: 0.8397\n",
            "Epoch 22/24\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.7327 - acc: 0.8827 - lr: 0.33173 - momentum: 0.87 \n",
            "98/98 [==============================] - 25s 250ms/step - loss: 0.7331 - acc: 0.8824 - val_loss: 0.8361 - val_acc: 0.8540\n",
            "Epoch 23/24\n",
            "29/98 [=======>......................] - ETA: 16s - loss: 0.7081 - acc: 0.8910"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e4cb50125d23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m model.fit_generator(generator=gen,steps_per_epoch=np.ceil(50000/512), epochs=24,  \n\u001b[0;32m---> 13\u001b[0;31m                                 validation_data = validation_iterator, verbose=1,callbacks =[olr])\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# print (\"Model took %0.2f seconds to train\"%(end - start))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GscvKzZLFKi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "f5ef08a2-1d2b-4a9b-ce95-fd07507ea67c"
      },
      "source": [
        "model.fit_generator(generator=gen,steps_per_epoch=np.ceil(50000/512), epochs=6,  \n",
        "                                validation_data = validation_iterator, verbose=1,callbacks =[olr])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3494 - acc: 0.9420 - lr: 0.03136 - momentum: 0.94 \n",
            "98/98 [==============================] - 23s 236ms/step - loss: 0.3488 - acc: 0.9423 - val_loss: 0.5183 - val_acc: 0.8974\n",
            "Epoch 2/6\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2690 - acc: 0.9697 - lr: 0.05495 - momentum: 0.94 \n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.2687 - acc: 0.9699 - val_loss: 0.5005 - val_acc: 0.9038\n",
            "Epoch 3/6\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2514 - acc: 0.9743 - lr: 0.07855 - momentum: 0.93 \n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.2509 - acc: 0.9745 - val_loss: 0.5030 - val_acc: 0.9054\n",
            "Epoch 4/6\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2469 - acc: 0.9753 - lr: 0.10215 - momentum: 0.93 \n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.2468 - acc: 0.9753 - val_loss: 0.4997 - val_acc: 0.9029\n",
            "Epoch 5/6\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2432 - acc: 0.9746 - lr: 0.12574 - momentum: 0.92 \n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.2436 - acc: 0.9745 - val_loss: 0.5268 - val_acc: 0.9015\n",
            "Epoch 6/6\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2443 - acc: 0.9740 - lr: 0.14934 - momentum: 0.91 \n",
            "98/98 [==============================] - 23s 236ms/step - loss: 0.2445 - acc: 0.9740 - val_loss: 0.5429 - val_acc: 0.8921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fec70783d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK_kLsmxLvUJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6cc71b7a-ea1e-4a40-9bec-0878a39b19e9"
      },
      "source": [
        "model.fit_generator(generator=gen,steps_per_epoch=np.ceil(50000/512), epochs=3,  \n",
        "                                validation_data = validation_iterator, verbose=1,callbacks =[olr])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2466 - acc: 0.9731 - lr: 0.03136 - momentum: 0.94 \n",
            "98/98 [==============================] - 23s 236ms/step - loss: 0.2462 - acc: 0.9732 - val_loss: 0.4960 - val_acc: 0.9032\n",
            "Epoch 2/3\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2192 - acc: 0.9809 - lr: 0.05495 - momentum: 0.94 \n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.2189 - acc: 0.9811 - val_loss: 0.4887 - val_acc: 0.9014\n",
            "Epoch 3/3\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2158 - acc: 0.9828 - lr: 0.07855 - momentum: 0.93 \n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.2157 - acc: 0.9828 - val_loss: 0.4919 - val_acc: 0.9041\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fec70783198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgwIhCP8pe5_",
        "colab_type": "code",
        "outputId": "acc07c64-a795-41fb-d1c1-031d633c7814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# compute test accuracy\n",
        "result = model.evaluate_generator(validation_iterator, steps = len(validation_iterator))\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.43652025163173674, 0.9149]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9lgMpGjJG1C",
        "colab_type": "code",
        "outputId": "f2fac2a1-4ac1-45a6-e8af-22fe273178ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "layer = [layer for layer in model.layers[0:] if type(layer)==Conv2D][-2]\n",
        "olr.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njCkVKwxjjDGlYoVhjDGmVP4/o4VC+fmsWiUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}