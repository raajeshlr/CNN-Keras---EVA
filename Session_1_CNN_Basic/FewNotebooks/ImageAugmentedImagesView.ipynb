{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CustomGenerator-and-ImgAug-on-CIFAR-10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpHw7RmGWz6o",
        "colab_type": "text"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRx50GTG5irV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prerequisites for imgaug library\n",
        "!pip install six numpy scipy Pillow matplotlib scikit-image opencv-python imageio Shapely"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3A0x7su5oPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image augmentation library imgaug (https://github.com/aleju/imgaug)\n",
        "!pip install imgaug\n",
        "\n",
        "# NOTE: make sure to Restart Runtime after this installation completes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ1cVrDVB8nE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imgaug needs latest scikit module. so need to do this. else, will get some weird error related to numpy!\n",
        "!pip install --upgrade scikit-image\n",
        "\n",
        "# NOTE: make sure to Restart Runtime after this installation completes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvydk2dYW3P1",
        "colab_type": "text"
      },
      "source": [
        "# Test to ensure imgaug library works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7aUgeBNTiSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example from imgaug...just to check if the library works properly after installing\n",
        "import imageio\n",
        "import imgaug as ia\n",
        "%matplotlib inline\n",
        "\n",
        "image = imageio.imread(\"https://upload.wikimedia.org/wikipedia/en/7/7d/Lenna_%28test_image%29.png\")\n",
        "\n",
        "print(\"Original:\")\n",
        "ia.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bK-RMhuWGqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "ia.seed(4)\n",
        "\n",
        "rotate = iaa.Affine(rotate=(-25, 25))\n",
        "image_aug = rotate.augment_image(image)\n",
        "\n",
        "print(\"Augmented:\")\n",
        "ia.imshow(image_aug)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN6VpfcnW_NM",
        "colab_type": "text"
      },
      "source": [
        "# Example template to show usage of Custom generator and imgaug library "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSD5oF0i5cd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# usual model definition code\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# params as usual\n",
        "num_classes = 200 \n",
        "IMAGE_WIDTH = 32 \n",
        "IMAGE_HEIGHT = 32 \n",
        "NUM_CHANNELS = 3\n",
        "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS)\n",
        "BATCH_SIZE = 100\n",
        "NUM_EPOCHS = 10\n",
        "VAL_IMAGES = 10000 \n",
        "\n",
        "# define network\n",
        "model = Sequential()\n",
        "...\n",
        "...\n",
        "...\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThEZdP8x5tWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# update the path to train & val folders\n",
        "train_data_dir = '/content/<path to train folder>'\n",
        "validation_data_dir = '/content/<path to val folder>'\n",
        "\n",
        "\n",
        "# Custom Generator & ImgAug\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "\n",
        "# define the augmentations needed as methods. \n",
        "# NOTE: we can leverage any image aug library in these methods to do needed augmentation. in this example, we have used imgaug library\n",
        "def rotate_image(batches, angle):\n",
        "  seq = iaa.Affine(rotate=(-angle, angle)) \n",
        "  # using rotate as example. check imgaug doc for more https://imgaug.readthedocs.io/en/latest/source/api.html \n",
        "  while True:\n",
        "    batch_x, batch_y = next(batches)\n",
        "    #print('batch_x.shape[0]: ', batch_x.shape[0]) # batch size\n",
        "    #print('batch_x.shape[1]: ', batch_x.shape[1]) # image width\n",
        "    #print('batch_x.shape[2]: ', batch_x.shape[2]) # image height\n",
        "    #print('batch_x[i].shape: ', batch_x[0].shape) # input image dims\n",
        "    batch_rotate = np.zeros((batch_x.shape[0], batch_x.shape[1], batch_x.shape[2], NUM_CHANNELS)) \n",
        "    # NOTE: imgaug works on color images (3 channels). doesn't work on greyscale images with one channel\n",
        "    for i in range(batch_x.shape[0]):\n",
        "       batch_rotate[i] = seq.augment_image(batch_x[i]) # calling ImgAug's augmentation on a single image\n",
        "    yield (batch_rotate, batch_y)\n",
        "\n",
        "# NOTE: in the above method, only one augmentation is defined. \n",
        "# ideally, we could define multiple augs in a method by declaring Sequential as array, and mention the % of images to apply aug using 'Simetimes' API \n",
        "# example:\n",
        "def blur_crop_flip_image(batches, blur_value, crop_value, flip_value):\n",
        "  seq = iaa.Sequential([\n",
        "    iaa.GaussianBlur(sigma=(0, blur_value)), # ex: 0.4\n",
        "    iaa.Crop(percent=(0, crop_value)), # ex: 0.2\n",
        "    iaa.Sometimes(0.3, iaa.Fliplr(flip_value))]) # 50% flip / horizontal flip of only 30% of the images passed\n",
        "  while True:\n",
        "    batch_x, batch_y = next(batches)\n",
        "    batch_augmented = np.zeros((batch_x.shape[0], batch_x.shape[1], batch_x.shape[2], NUM_CHANNELS)) \n",
        "    # NOTE: imgaug works on color images (3 channels). doesn't work on greyscale images with one channel\n",
        "    batch_augmented = seq.augment_images(batch_x) # calling ImgAug's augmentation on a batch of images\n",
        "    yield (batch_augmented, batch_y)\n",
        "  \n",
        "# leveraging Kera's image data generator to read input images in batches from the train directories for augmentation\n",
        "# Note that we just using zoom option in imagedatagenerator. ideally can use any other aug as well if needed. \n",
        "# but remember that the augs defined in data generaor will be applied to batch of images read from directory, before passing to our ImgAug aug.\n",
        "# so, if these only imgaug's augmentation is required, create an ImageDataGenerator without any params/augs\n",
        "\n",
        "train_datagen = ImageDataGenerator(zoom_range=0.2, fill_mode='nearest') \n",
        "train_batches = train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                  target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
        "                                                  class_mode='categorical',\n",
        "                                                  shuffle=True,\n",
        "                                                  batch_size=BATCH_SIZE)\n",
        "\n",
        "# passing the batch of images from flow_from_dir to our data aug method. angle of rotation is 25 \n",
        "train_generator = rotate_image(train_batches, 25) \n",
        "\n",
        "# NOTE:\n",
        "# if needed, we could use few default augs from keras data generator (generator1) and create another custom data generator (generator2)\n",
        "# with ImgAug based augmentations and then use zip both generators (generator1 & 2) to combine them together\n",
        "# check the exampe in keras doc - https://keras.io/preprocessing/image/ (search for 'train_generator = zip(image_generator, mask_generator)')\n",
        "\n",
        "# no augs on validation images, so empty ImageDataGenerator. can do if needed\n",
        "valid_datagen = ImageDataGenerator() \n",
        "validation_generator = valid_datagen.flow_from_directory(validation_data_dir,\n",
        "                                                  target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
        "                                                  class_mode='categorical',\n",
        "                                                  shuffle=False,\n",
        "                                                  batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABEd_sdbADux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use the generators as usual in fit_generator\n",
        "\n",
        "# make sure to update the steps_per_epoch & validation_steps properly\n",
        "# in case you are using custom generator with aug for validation data as well, then replace VAL_IMAGES with validation_batches.sample\n",
        "# NOTE: do not forget to use // for dividing, as it returns an int. just / returns float\n",
        "# NOTE: int() in caculating steps_per_epoch & validation_steps is not required as dividing by // returns int\n",
        "history = model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=int(train_batches.samples//BATCH_SIZE), \n",
        "                    epochs=NUM_EPOCHS, verbose=2, \n",
        "                    validation_steps=int(VAL_IMAGES//BATCH_SIZE), \n",
        "                    validation_data=validation_generator)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLB92SsbyEGj",
        "colab_type": "text"
      },
      "source": [
        "# Class weights : custom implementation\n",
        "\n",
        "**Disclaimer:** have only done unit testing of the code...yet to pass the calculated class_weights to fit_generator for training\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Definition of class_weight from keras documentation:**\n",
        "\n",
        "**class_weight:** Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM-rPTLGyFgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# custom method that takes in a dict of 'label' vs. 'number of correct predictions' as input and generates dict of 'label' vs. 'weight' that can be passed to fit_generator\n",
        "\n",
        "#\n",
        "# NOTE: CHANGE IN PARAM to be passed...the dict should contain 'label' vs. 'number of CORRECT predictions' (and NOT 'number of hard samples')\n",
        "#\n",
        "\n",
        "def get_class_weights(dict_labels_vs_samples, balanced=True):\n",
        "  # param dict_labels_vs_samples: dict of 'label' vs. 'number of correct predictions'\n",
        "  # param balanced: if True, will produce class weights considering max samples count - % of augmented images per class will be proportional to max count of samples \n",
        "  # param balanced: if False, will produce class weights considering average samples count - % of aumented images per class will be proportional to avg samples of classes\n",
        "  \n",
        "  if not len(dict_labels_vs_samples) == 0:\n",
        "    print('WARNING: dict passed is NOT of length 200 - meaning not all 200 classes are included in the dict')\n",
        "    \n",
        "  keys = dict_labels_vs_samples.keys()\n",
        "  values = list(dict_labels_vs_samples.values())\n",
        "  total_samples = sum(values)\n",
        "  num_classes = len(values)\n",
        "  max_of_all_classes = max(values)\n",
        "  average_of_all_classes = total_samples / num_classes\n",
        "  multiplying_factor = 1\n",
        "  \n",
        "  if balanced:\n",
        "    multiplying_factor = max_of_all_classes / average_of_all_classes\n",
        "  \n",
        "  print('total_samples: ', total_samples)\n",
        "  print('num_classes: ', num_classes)\n",
        "  print('max_of_all_classes: ', max_of_all_classes)\n",
        "  print('multiplying_factor: ', multiplying_factor)\n",
        "  \n",
        "  class_weight = dict()\n",
        "\n",
        "  for key in keys:\n",
        "        num_correct_pred = int(dict_labels_vs_samples.get(key))\n",
        "        if num_correct_pred == 0:\n",
        "          num_correct_pred = 1 # this is to avoid divide by zero error, if a class has no correct predictions\n",
        "        score_for_class = (total_samples / (num_classes * num_correct_pred)) * multiplying_factor\n",
        "        class_weight[key] = score_for_class\n",
        "        \n",
        "  return class_weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXuCLRTpyHR9",
        "colab_type": "code",
        "outputId": "9c9f5bbe-1453-4627-c180-c433e7b3f7cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "dict_labels_and_samples = {'label1':25, 'label2':15, 'label3':30, 'label4':60}\n",
        "class_weights = get_class_weights(dict_labels_and_samples, True)\n",
        "print(class_weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total_samples:  130\n",
            "num_classes:  4\n",
            "max_of_all_classes:  60\n",
            "multiplying_factor:  1.8461538461538463\n",
            "{'label1': 2.4000000000000004, 'label2': 4.0, 'label3': 2.0, 'label4': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}